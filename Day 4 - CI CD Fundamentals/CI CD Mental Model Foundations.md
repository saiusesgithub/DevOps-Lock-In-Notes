# ğŸ§  CI/CD MENTAL MODEL â€” FOUNDATIONS (REFERENCE NOTES)

> These notes are meant to be **revisited in the future**.
> Not exam-oriented. Not tool-oriented.
> This is the **mental model** that makes CI/CD feel obvious instead of magical.

---

## 1ï¸âƒ£ What problem CI/CD actually solves (WHY it exists)

Before CI/CD, the typical workflow looked like this:

* Developer writes code
* Tests locally (sometimes)
* Pushes code
* Something breaks in someone elseâ€™s environment
* Debugging starts with: *â€œIt works on my machineâ€*

CI/CD exists to **remove uncertainty**.

Its real goal:

> **Make the computer verify your assumptions every time you change code.**

Automation replaces trust.

---

## 2ï¸âƒ£ CI â‰  CD (conceptual separation, not just definitions)

### Continuous Integration (CI)

CI is about **confidence**.

CI answers:

> â€œIs this version of the code internally consistent?â€

CI typically includes:

* Building the project
* Running automated tests
* Static checks (lint, format, type checks)
* Sanity validations (does it start? does it build?)

Important:

* CI runs **on every change** (push / PR)
* CI does **not** affect users
* CI is purely a **gatekeeper**

Think of CI as:

> A robot reviewer that never gets tired and never forgets to check things.

---

### Continuous Delivery / Deployment (CD)

CD is about **release**, not correctness.

CD answers:

> â€œShould this version go live?â€

CD may include:

* Deploying to staging / prod
* Restarting services
* Migrating databases
* Notifying teams

Key distinction:

* **CI checks correctness**
* **CD changes real systems**

This is why CI must be rock-solid before CD is attempted.

---

## 3ï¸âƒ£ The most important idea: CI is just a Linux machine

Forget tools. Forget YAML.

At its core:

> **CI = a computer running commands for you automatically**

That computer is:

* A temporary **Linux machine** (called a runner)
* Usually Ubuntu
* Created fresh for every run
* Destroyed after the run finishes

Nothing persists unless you explicitly save it.

This single idea explains:

* Why things break in CI but work locally
* Why missing dependencies cause failures
* Why environment assumptions are dangerous

---

## 4ï¸âƒ£ Fresh machine mindset (THIS SAVES YOU HOURS)

Every CI run starts like this:

* Empty filesystem (except OS)
* No project files
* No Docker images
* No running containers
* No environment variables (except defaults)

So CI forces you to be explicit:

* Explicit installs
* Explicit builds
* Explicit configuration

Mental rule:

> If you didnâ€™t write it in the pipeline, it doesnâ€™t exist.

---

## 5ï¸âƒ£ Pipelines, jobs, and steps (conceptual, not YAML yet)

A **pipeline** is simply:

> A sequence of automated actions triggered by an event

Conceptually:

* Event happens (push)
* Machine starts
* Commands run top-to-bottom
* Result is pass or fail

Inside a pipeline:

* **Jobs** group related work
* **Steps** are individual commands

Key behavior:

* Steps execute sequentially
* Failure stops execution

This mirrors how you work in a terminal.

---

## 6ï¸âƒ£ Why CI failures are predictable (logs + exit codes)

CI failures are not random.
They are deterministic.

A command can only do two things:

* Succeed
* Fail

This is communicated via:

### Logs

* Standard output
* Error output
* Messages printed by tools

### Exit codes

* `0` â†’ success
* non-zero â†’ failure

CI systems watch exit codes.
If a command returns non-zero:

* step fails
* job fails
* pipeline turns red âŒ

---

## 7ï¸âƒ£ Debugging CI = debugging Linux

CI debugging is **not** a special skill.
It is normal Linux debugging.

The only difference:

* You debug via logs instead of an interactive terminal

Standard debug flow:

1. Identify the failed step
2. Identify the command
3. Read logs carefully
4. Find the *first* real error
5. Fix the root cause

Never debug from the last line upward blindly.

---

## 8ï¸âƒ£ Where Docker fits in CI (conceptually)

When you run Docker in CI:

* Docker runs **inside the Linux runner**
* `docker build` behaves exactly like local Docker

This is powerful because:

* Dockerfile becomes the contract
* CI verifies the contract on every push

If Docker build fails in CI:

* Your project is **objectively broken**
* Not â€œbroken on my machineâ€

---

## 9ï¸âƒ£ Why people struggle with CI/CD

Most people fail because:

* They treat CI as magic
* They copy YAML without understanding
* They donâ€™t think in terms of machines

Correct mindset:

> â€œCI is me, on a fresh Linux server, running commands automatically.â€

Once you think this way:

* YAML becomes boring
* Errors become readable
* Fixes become obvious

---

## ğŸ”Ÿ Mental checklist (lock this before execution)

You should be able to say:

* CI checks correctness, CD deploys
* CI runs on a fresh Linux machine
* Pipelines execute commands sequentially
* Failures come from logs + exit codes
* Debugging CI = debugging Linux

If this feels natural now, you are ready.